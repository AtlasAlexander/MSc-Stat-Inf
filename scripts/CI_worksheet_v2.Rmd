---
title: "Confidence Intervals worksheet"
author: "Statistical Inference Team"
date: "26/10/2023"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(readr)
```


## Computing CIs: an example with fake data

Repeating the example from the preparatory reading

```{r simple_fake_data}
x <- rnorm(52, 50, 5)
fake <- data.frame(x=x)
fake %>%
  ggplot(aes(x)) +
  geom_histogram(binwidth = 5)
```

Calculate confidence interval using R modelling routines:

```{r CI_from_model}
model_1 <- lm(x ~ 1, data = fake)
confint(model_1, level=0.95)
```

## Dewis practice on confidence intervals

There is a Dewis practice assessment on confidence intervals. 
Question 1 checks your ability to write simple R code.
In this case, it is practice of

- storing data in R (remember the function `read.csv`)
- calculating summary statistics (remember the function `summary`)
- calculating confidence intervals (adapt the code used above)
- Question 2 gives you practice at interpreting confidence intervals.

```{r dewis_confidence_intervals}

# In here, type in your code for Question 1 of the Dewis practice assessment on confidence intervals
summary(contents_6)
sd(contents_6$IQ)
model_1 <- lm(IQ ~ 1, data = contents_6)
confint(model_1, level=0.95)

```

### [Advanced] Extension to Question 2

In the code chunk below, write some R code that generates fake data with similar properties to Sample A and Sample B.
Then calculate confidence intervals for the mean of sample A and the mean of sample B.
Finally, apply the independent samples t-test to determine if there is a significant difference between the means of sample A and the mean of sample B.

```{r extension}
# Space to write code for extension to Question 2
x <- rnorm(15, 113.4, 13)
fake <- data.frame(x=x)
fake %>%
  ggplot(aes(x)) +
  geom_histogram(binwidth = 5)

model_1 <- lm(x ~ 1, data = fake)
confint(model_1, level=0.95)

t.test(x, contents_6,
      alternative = c("two.sided"), conf.level = 0.95)
```


## A generic rule of thumb for a 95% Confidence Interval

$$\hat{\theta} \pm 2 \times se(\hat{\theta})$$

This rule of thumb is worth memorising. It can be really useful, whether working with written reports or when wanting a quick check on some data analysis.

To rehearse the rule of thumb, we will calculate a 95 percent confidence interval using:

$$\bar{x} \pm 2 \times \mbox{standard error of the mean}$$

where 

$$\mbox{standard error of the mean} = \frac{sd}{\sqrt{n}}$$


### Challenge: Complete the code to calculate the confidence limits

```{r, calculate_ci_manually}

# You need to modify this code chunk before it will run successfully.

sample_mean <- mean(fake$x)
sample_sd <- sd(fake$x)
n <- length(fake$x)
#se_mean <- # complete this calculation
#lower_ci <- # complete this calculation
#upper_ci <- # complete this calculation
#sprintf("95 percent CI for the mean: %f - %f", lower_ci, upper_ci)
```

Compare your results with those you get from the R modelling routines (above):

Any comments or observations on the "hand" calculated 95% CI and the model calculated 95% CI?

NOTE: We will usually use the modelling routines within R, this exercicse gives you an idea of how you could compute an approximate result yourself if you needed to.

## Summary

- Don't panic that we are going to expect you to learn many methods for creating "good" confidence intervals
- Do note that on real data, sometimes the textbook methods don't work and you need to be able to call this out.
- This week, concentrate on the learning points. What is a confidence interval e.g., what should it tell us, why use a 90%, 95% or 99% interval.
- Soon we will look at the "Bootstrap" which provides a computationally intensive, but very general, way of computing a general purpose confidence interval that should behave in most circumstances.
